{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import torch\n",
    "import diffusers\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionInpaintPipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# surpress FutureWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text2Image (`StableDiffusionPipeline`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
    "pipeline = pipeline.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(\"a photo of an astronaut riding a horse on mars\").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# multiple prompts\n",
    "prompts = [\n",
    "    \"a photo of a dog working on his computer\", \n",
    "    \"a coffee cup with the periodic table of elements painted on it\", \n",
    "    \"a 3D render of humanoid tree taking a walk with his tree wife\"\n",
    "    ]\n",
    "\n",
    "# different scheduler\n",
    "pipeline.scheduler = diffusers.DDPMScheduler.from_config(pipeline.scheduler.config)\n",
    "num_inference_steps = 150\n",
    "\n",
    "# guidance_scale\n",
    "guidance_scale = 12.5\n",
    "\n",
    "# run inference\n",
    "ret = pipeline(\n",
    "    prompts, \n",
    "    guidance_scale=guidance_scale, \n",
    "    num_inference_steps=num_inference_steps, \n",
    "    output_type=\"np.array\"\n",
    ")\n",
    "\n",
    "# plot results\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.imshow(np.hstack(ret.images))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inpainting (`StableDiffusionInpaintPipeline`)\n",
    "\n",
    "Let's assume you would like to train a under-age detector detecting children in webcam images. That is quite a challenge as collecting data from minors is challenging, legally and ethically. So let's use stable-diffusion and generate a dataset from children of different ages, gender and ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image and mask\n",
    "\n",
    "init_image = PIL.Image.open(\"data/chris_capture.jpg\").convert(\"RGB\").resize((512, 512))\n",
    "mask_face = PIL.Image.open(\"data/chris_mask_face.png\").convert(\"RGB\").resize((512, 512))\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15, 6))\n",
    "\n",
    "ax1.imshow(init_image)\n",
    "ax1.set_title(\"Initial Image\")\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "ax2.imshow(mask_face)\n",
    "ax2.set_title(\"Mask\")\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "ax3.imshow(init_image)\n",
    "ax3.imshow(mask_face, alpha=0.5)\n",
    "ax3.set_title(\"Masked Image\")\n",
    "ax3.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "pipeline = StableDiffusionInpaintPipeline.from_pretrained(\"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float16)\n",
    "pipeline = pipeline.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a first quick run to see it if works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First quick run with suboptimal settings \n",
    "\n",
    "prompt = f\"Face of a three year old, high resolution, looking into a webcam\"\n",
    "negative_prompt = \"black and white, asymmetric face\"\n",
    "num_inference_steps = 25\n",
    "guidance_scale = 7.5\n",
    "args = {\n",
    "    \"prompt\": prompt,\n",
    "    \"image\": init_image,\n",
    "    \"mask_image\": mask_face,\n",
    "    \"negative_prompt\": negative_prompt, \n",
    "    \"num_inference_steps\": num_inference_steps,\n",
    "    \"guidance_scale\": 7.5,\n",
    "    \"num_images_per_prompt\": 3,\n",
    "    \"output_type\": \"np.array\"\n",
    "}\n",
    "images = pipeline(**args).images\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.imshow(np.hstack(images))\n",
    "plt.title(f\"Prompt: {prompt}\\nNegative Prompt: {negative_prompt}\\nScheduler: {pipeline.scheduler._class_name}\\nSteps: {num_inference_steps}\\nGuidance Scale: {guidance_scale}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's experiment with different schedulers and steps to get a feeling for how these parameters affect how photorealistic images look in the end. We'd expect the DDIM scheduler to outperform the others for low number of steps but to saturate in performance after about 50 steps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing different schedulers and steps\n",
    "\n",
    "steps = [25, 50, 100, 150, 250, 500]\n",
    "\n",
    "schedular_config = pipeline.scheduler.config\n",
    "schedulers = {\n",
    "    \"DDPM\": diffusers.DDPMScheduler.from_config(schedular_config),\n",
    "    \"DDIM\": diffusers.DDIMScheduler.from_config(schedular_config),\n",
    "    \"PNDM\": diffusers.PNDMScheduler.from_config(schedular_config),\n",
    "    \"Euler\": diffusers.EulerDiscreteScheduler.from_config(schedular_config)\n",
    "}\n",
    "\n",
    "prompt = \"Face of a three year old, high resolution, looking into a webcam\"\n",
    "negative_prompt = \"black and white, asymmetric face\"\n",
    "\n",
    "images = dict()\n",
    "for scheduler_name, scheduler in schedulers.items():\n",
    "    \n",
    "    print(f\"Running {scheduler_name} scheduler\")\n",
    "    pipeline.scheduler = scheduler\n",
    "    \n",
    "    images[scheduler_name] = dict()\n",
    "\n",
    "    for num_inference_steps in steps:\n",
    "        ret = pipeline(\n",
    "            prompt=prompt,\n",
    "            image=init_image,\n",
    "            mask_image=mask_face,\n",
    "            negative_prompt=negative_prompt, \n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=7.5,\n",
    "            num_images_per_prompt=3,\n",
    "            output_type=\"np.array\"\n",
    "        )\n",
    "        images[scheduler_name][num_inference_steps] = ret.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(steps), len(schedulers), figsize=(12, len(steps)*4))\n",
    "\n",
    "for i, scheduler_name in enumerate(schedulers.keys()):\n",
    "    for j, num_inference_steps in enumerate(steps):\n",
    "        axs[j, i].imshow(images[scheduler_name][num_inference_steps])\n",
    "        axs[j, i].set_title(f\"{scheduler_name} with {num_inference_steps} steps\")\n",
    "        axs[j, i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the PNDM scheduler with different ages, gender and ethnicities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.scheduler = schedulers[\"DDPM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "age_and_gender_list = [\n",
    "    \"two year old\", \n",
    "    \"three year old\" , \n",
    "    \"five year old girl\", \n",
    "    \"five year old boy\", \n",
    "    \"ten year old girl\", \n",
    "    \"ten year old boy\", \n",
    "    \"teenage girl\"\n",
    "    \"teenage boy\", \n",
    "]\n",
    "\n",
    "countries = [\"Europe\", \"China\", \"India\", \"Kenia\", \"Mexico\"]\n",
    "\n",
    "args = {\n",
    "    \"image\": init_image,\n",
    "    \"mask_image\": mask_face,\n",
    "    \"negative_prompt\":  \"black and white, asymmetric face\", \n",
    "    \"num_inference_steps\": 150,\n",
    "    \"guidance_scale\": 7.5,\n",
    "    \"num_images_per_prompt\": 3,\n",
    "    \"output_type\": \"np.array\",\n",
    "    \"generator\": [torch.Generator(device=\"cuda\").manual_seed(i) for i in range(3)]\n",
    "}\n",
    "\n",
    "for country in countries:\n",
    "    for age_and_gender in age_and_gender_list:\n",
    "\n",
    "        prompt = f\"Face of a {age_and_gender} from {country}, high resolution, webcam image\"\n",
    "        ret = pipeline(prompt, **args)\n",
    "\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        plt.imshow(np.hstack(ret.images))\n",
    "        plt.title(prompt)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "836760dba83a5e00882a2d235b852658fc499e8dc492d6a1a1bdc6a6abeb427e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
