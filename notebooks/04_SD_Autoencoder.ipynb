{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Variational Autoencoder</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lovely_tensors as lt\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ldm.models.autoencoder import AutoencoderKL\n",
    "\n",
    "from helper import ForwardDiffusionProcessor, download_images, X2imgs, imgs2X\n",
    "\n",
    "lt.monkey_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# laod the weights\n",
    "ckpt = \"../v2-1_512-ema-pruned.ckpt\"\n",
    "state_dict = torch.load(ckpt, map_location=\"cpu\")[\"state_dict\"]\n",
    "\n",
    "state_dict_vae = {}\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith(\"first_stage_model.\"):\n",
    "        state_dict_vae[k.replace(\"first_stage_model.\", \"\")] = v\n",
    "\n",
    "# load the parameters\n",
    "config_path = \"../configs/stable-diffusion/v2-inference.yaml\"\n",
    "cfg = OmegaConf.load(config_path)\n",
    "\n",
    "# load the variational autoencoder\n",
    "vae = AutoencoderKL(**cfg.model.params.first_stage_config.params)\n",
    "vae.load_state_dict(state_dict_vae, strict=True)\n",
    "vae.to(device)\n",
    "vae.eval()\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download some random images\n",
    "imgs = download_images(n=5, res=512)\n",
    "plt.figure(figsize=(20, 3))\n",
    "plt.imshow(np.hstack(imgs))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoding all images\n",
    "X = imgs2X(imgs, device)\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    posterior = vae.encode(X)\n",
    "    Z = posterior.sample()\n",
    "    X_tilde = vae.decode(Z)\n",
    "imgs_reconstructed = X2imgs(X_tilde)\n",
    "\n",
    "# Plot the result\n",
    "diff = np.abs(imgs - imgs_reconstructed)\n",
    "viz = np.vstack([\n",
    "        np.hstack(imgs),\n",
    "        np.hstack(imgs_reconstructed),\n",
    "        np.hstack(diff)\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(20, 9))\n",
    "plt.imshow(viz)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value ranges of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencode_random_image():\n",
    "\n",
    "    imgs = download_images(n=1, res=512)\n",
    "    \n",
    "    X = imgs2X(imgs, device)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        posterior = vae.encode(X)\n",
    "        Z = posterior.sample()\n",
    "        X_tilde = vae.decode(Z)\n",
    "    imgs_reconstructed = X2imgs(X_tilde)\n",
    "\n",
    "    latent = Z.cpu().numpy()\n",
    "    img = imgs[0]\n",
    "    img_reconstructed = imgs_reconstructed[0]\n",
    "\n",
    "    return img, img_reconstructed, latent\n",
    "\n",
    "n = 100\n",
    "latents = []\n",
    "for _ in tqdm(range(n)):\n",
    "    _, _, latent = autoencode_random_image()\n",
    "    latents.append(latent)\n",
    "latents = np.vstack(latents)\n",
    "\n",
    "print(\"Mean value of the latent space: \", np.mean(latents))\n",
    "print(\"Std value of the latent space:  \", np.std(latents))\n",
    "print(\"1/cfg.model.params.scale_factor:\", 1/cfg.model.params.scale_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Little Appendix on how bad the L1 norm is for image reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, img_reconstructed, latent = autoencode_random_image()\n",
    "\n",
    "bboxs = [\n",
    "    (50, 60, 50, 60),\n",
    "    (200, 250, 50, 100),\n",
    "    (300, 350, 300, 350),\n",
    "]\n",
    "diff = np.abs(img - img_reconstructed).mean(axis=-1)\n",
    "\n",
    "fig, axs = plt.subplots(len(bboxs) + 1, 3, figsize=(9, 12))\n",
    "\n",
    "axs[0,0].imshow(img)\n",
    "axs[0,1].imshow(img_reconstructed)\n",
    "axs[0,2].imshow(diff, cmap=\"Reds\", vmin=0, vmax=255)\n",
    "axs[0,2].set_title(f\"Mean absolute difference: {diff.mean():.2f}\")\n",
    "\n",
    "for i, bbox in enumerate(bboxs):\n",
    "    i1, i2, j1, j2 = bbox\n",
    "    img_ = img[i1:i2, j1:j2]\n",
    "    img_reconstructed_ = img_reconstructed[i1:i2, j1:j2]\n",
    "    diff_ = diff[i1:i2, j1:j2]\n",
    "\n",
    "    axs[i+1,0].imshow(img_)\n",
    "    axs[i+1,1].imshow(img_reconstructed_)\n",
    "    axs[i+1,2].imshow(diff_, cmap=\"Reds\", vmin=0, vmax=255)\n",
    "    axs[i+1,2].set_title(f\"Mean absolute difference: {diff_.mean():.2f}\")\n",
    "\n",
    "    for j in range(3):\n",
    "        # add bounding box in original image\n",
    "        axs[0,j].plot([j1,j1,j2,j2,j1], [i1,i2,i2,i1,i1], color=\"red\", linewidth=2)\n",
    "\n",
    "        # add a grind\n",
    "        [axs[i+1,j].axhline(_i, color=\"black\", linestyle=\"--\") for _i in np.linspace(i1, i2, 7)[1:-1] - i1]\n",
    "        [axs[i+1,j].axvline(_j, color=\"black\", linestyle=\"--\") for _j in np.linspace(j1, j2, 7)[1:-1] - j1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4895cdc8b443a3a23981640910a32e7a59b10b569d9d0b54f5319973a233b4b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
